{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJJo6cNoNdUZ",
        "outputId": "5e71c480-99ed-4e1d-810b-ee74fb0906b4"
      },
      "id": "qJJo6cNoNdUZ",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ebd68ed",
      "metadata": {
        "id": "5ebd68ed"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d04137c",
      "metadata": {
        "id": "7d04137c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "all_df = pd.read_json('/content/drive/MyDrive/LinkData/dtp_uz/Database/dtp_uz.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d16093b9",
      "metadata": {
        "id": "d16093b9"
      },
      "outputs": [],
      "source": [
        "\n",
        "def new_dict_(k, v, parent_key=''):\n",
        "    \"\"\"\n",
        "    Function to flatten a dictionary with nested structures.\n",
        "    \"\"\"\n",
        "    items = []\n",
        "    new_key = f\"{parent_key}_{k}\" if parent_key else k\n",
        "\n",
        "    if isinstance(v, dict):\n",
        "        for sub_key, sub_value in v.items():\n",
        "            items.extend(new_dict_(sub_key, sub_value, new_key).items())\n",
        "    elif isinstance(v, list):\n",
        "        for num, elem in enumerate(v, start=1):\n",
        "            if isinstance(elem, dict):\n",
        "                items.extend(new_dict_(num, elem, new_key).items())\n",
        "            else:\n",
        "                items.append((f\"{new_key}_{num}\", elem))\n",
        "    else:\n",
        "        items.append((new_key, v))\n",
        "\n",
        "    return dict(items)\n",
        "\n",
        "# Assuming all_df['results'][0] is a dictionary\n",
        "\n",
        "all_data = []\n",
        "for index_ in all_df.index:\n",
        "    new_dict = {}\n",
        "    for key, value in all_df['results'][index_].items():\n",
        "        new_dict.update(new_dict_(key, value))\n",
        "\n",
        "    # Now new_dict contains the flattened structure\n",
        "\n",
        "    new_dict.update({'num_participants' : len(all_df['results'][0]['participants'])})\n",
        "    new_dict.update({'num_vehicles' : len(all_df['results'][0]['vehicles'])})\n",
        "    all_data.append(new_dict)\n",
        "    # len(new_dict)\n",
        "len(all_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "712223dc",
      "metadata": {
        "id": "712223dc"
      },
      "outputs": [],
      "source": [
        "df_need = pd.DataFrame(all_data)\n",
        "df_need.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "705f1b56",
      "metadata": {
        "id": "705f1b56"
      },
      "outputs": [],
      "source": [
        "# To SQL\n",
        "import sqlite3\n",
        "conn = sqlite3.connect(\"/content/drive/MyDrive/LinkData/dtp_uz/Database/dtp_uz.db\")\n",
        "df_need.to_sql(\"dtp_uz\", conn, if_exists='append', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d825e133",
      "metadata": {
        "id": "d825e133"
      },
      "outputs": [],
      "source": [
        "# Read SQL\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "conn = sqlite3.connect(\"/content/drive/MyDrive/LinkData/dtp_uz/Database/dtp_uz.db\")\n",
        "df_need_sql = pd.read_sql(\"SELECT * FROM dtp_uz\", conn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da99a7d7",
      "metadata": {
        "id": "da99a7d7"
      },
      "outputs": [],
      "source": [
        "print(df_need_sql.shape)\n",
        "df_need_sql.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d0075e9",
      "metadata": {
        "id": "0d0075e9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9690d9ce",
      "metadata": {
        "id": "9690d9ce"
      },
      "outputs": [],
      "source": [
        "df_need_sql_ = df_need_sql.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "a943b067",
      "metadata": {
        "id": "a943b067"
      },
      "outputs": [],
      "source": [
        "df_need_sql = df_need_sql_.copy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop columns with NaNs 100% of the time\n",
        "\n",
        "df_need_sql = df_need_sql.applymap(lambda x: x if x != '' else None)\n",
        "\n",
        "cols_ = df_need_sql.columns[df_need_sql.isna().all()]\n",
        "\n",
        "df_need_sql.dropna(axis=1, how='all', inplace=True)\n",
        "\n",
        "filter_accident_number = df_need_sql['accident_number'].isna()\n",
        "df_need_sql.drop(df_need_sql[filter_accident_number].index, inplace=True)\n",
        "\n",
        "\n",
        "df_need_sql['year_'] = df_need_sql['date_accident'].apply(lambda x: int(x[:4]))\n",
        "\n",
        "filter_year = df_need_sql['year_'] < 2010\n",
        "df_need_sql.drop(df_need_sql[filter_year].index, inplace=True)\n",
        "# df_need_sql['year_'].value_counts()\n"
      ],
      "metadata": {
        "id": "PLtr4ufHzkLK"
      },
      "id": "PLtr4ufHzkLK",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f0a7c83",
      "metadata": {
        "id": "7f0a7c83"
      },
      "outputs": [],
      "source": [
        "col_need = df_need_sql.columns\n",
        "col_need = col_need[col_need.str.contains('violation') & col_need.str.contains('id')]\n",
        "\n",
        "# Col string\n",
        "df_need_sql[col_need] = df_need_sql[col_need].applymap(str)\n",
        "\n",
        "# Set\n",
        "df_need_sql['violation_sets'] = df_need_sql.loc[:, col_need].apply(lambda x: set(x), axis=1)\n",
        "\n",
        "# Discard None\n",
        "for i in df_need_sql.index:\n",
        "    df_need_sql['violation_sets'][i].discard('nan')\n",
        "\n",
        "# Function to convert list to string and remove NaNs\n",
        "def convert_list_to_string(lst):\n",
        "    # Filter out NaN values and convert each item to string\n",
        "    return '/'.join([str(item) for item in lst if pd.notna(item)])\n",
        "\n",
        "# df_need_sql['violation_sets'] = df_need_sql['violation_sets'].apply(list)\n",
        "df_need_sql['len_violation_sets'] = df_need_sql['violation_sets'].apply(len)\n",
        "\n",
        "# Apply the function to the violation_sets column\n",
        "df_need_sql['violation_sets'] = df_need_sql['violation_sets'].apply(convert_list_to_string)\n",
        "\n",
        "\n",
        "\n",
        "print(df_need_sql['len_violation_sets'].unique())\n",
        "print()\n",
        "df_need_sql.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col_need = df_need_sql.columns\n",
        "col_need = col_need[col_need.str.contains('participants') & col_need.str.contains('gender')]\n",
        "\n",
        "# # Col string\n",
        "df_need_sql[col_need] = df_need_sql[col_need].applymap(str)\n",
        "\n",
        "# Set\n",
        "df_need_sql['gender_list'] = df_need_sql.loc[:, col_need].apply(lambda x: list(x), axis=1)\n",
        "\n",
        "# Drop None or NaN values from lists in the 'violation_sets' column\n",
        "df_need_sql['gender_list'] = df_need_sql['gender_list'].apply(lambda x: [item for item in x if item != 'None'])\n",
        "df_need_sql['len_gender_list'] = df_need_sql['gender_list'].apply(len)\n",
        "\n",
        "# Function to count occurrences of 'Male' and 'Female' in a list\n",
        "def count_gender_occurrences(lst):\n",
        "    male_count = lst.count('male')\n",
        "    female_count = lst.count('female')\n",
        "    return male_count, female_count\n",
        "\n",
        "# Apply the count_gender_occurrences function to each list in the 'gender_list' column\n",
        "df_need_sql[['male_count', 'female_count']] = df_need_sql['gender_list'].apply(lambda x: pd.Series(count_gender_occurrences(x)))\n",
        "\n",
        "df_need_sql.iloc[:, -5:]"
      ],
      "metadata": {
        "id": "ge-QPLrXzkNT"
      },
      "id": "ge-QPLrXzkNT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0d85498",
      "metadata": {
        "id": "b0d85498"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Convert the 'datetime_column' to datetime objects\n",
        "df_need_sql['date_accident'] = pd.to_datetime(df_need_sql['date_accident'], format=\"%Y-%m-%dT%H:%M:%S\")\n",
        "\n",
        "# Extract hours from the datetime column\n",
        "df_need_sql['day_of_week'] = df_need_sql['date_accident'].apply(lambda x: x.weekday())\n",
        "df_need_sql['day_name'] = df_need_sql['date_accident'].apply(lambda x: x.strftime(\"%A\"))\n",
        "df_need_sql['day_hour'] = df_need_sql['date_accident'].apply(lambda x: x.hour)\n",
        "\n",
        "df_need_sql['day_name'] = df_need_sql['day_name'].str.replace(\"Monday\", \"Dushanba\")\\\n",
        "                                               .str.replace(\"Tuesday\", \"Seshanba\")\\\n",
        "                                               .str.replace(\"Wednesday\", \"Chorshanba\")\\\n",
        "                                               .str.replace(\"Thursday\", \"Payshanba\")\\\n",
        "                                               .str.replace(\"Friday\", \"Juma\")\\\n",
        "                                               .str.replace(\"Saturday\", \"Shanba\")\\\n",
        "                                               .str.replace(\"Sunday\", \"Yakshanba\")\n",
        "\n",
        "df_need_sql.iloc[:,-10:]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_need_sql.shape"
      ],
      "metadata": {
        "id": "LqB-g9SazkPv"
      },
      "id": "LqB-g9SazkPv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To SQL\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "\n",
        "conn = sqlite3.connect(\"/content/drive/MyDrive/LinkData/dtp_uz/Database/dtp_uz_27012024.db\")\n",
        "df_need_sql.to_sql(\"dtp_uz\", conn, if_exists='append', index=False)"
      ],
      "metadata": {
        "id": "oUCPgEpbzkTH"
      },
      "id": "oUCPgEpbzkTH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21971f80",
      "metadata": {
        "id": "21971f80"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f86d4d6",
      "metadata": {
        "id": "9f86d4d6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}